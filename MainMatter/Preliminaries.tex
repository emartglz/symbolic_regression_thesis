\chapter{Preliminares}\label{chapter:preliminaries}

En el capítulo anterior se definió el objetivo de este trabajo, para ello se plantearon los conceptos de sistema de ecuaciones diferenciales lineales en los parámetros y la relación que existe entre ajustar un conjunto de datos y el algoritmo de mínimos cuadrados.

En la sección 1.1 de este capítulo se plantea lo que es una ecuación diferencial, en la sección siguiente se define de forma más detallada qué es una ecuación diferencial con respecto a los parámetros. Una técnica importante que se utilizó para el desarrollo de este trabajo es la regresión, los detalles se pueden encontrar en la sección 1.3. Las características ajuste cuadrático y regresión simbólica aparecen en las dos secciones siguientes respectivamente. A continuación en el capítulo se puede ver cómo se utiliza la regresión simbólica directamente en un sistema de ecuaciones diferenciales. En la última sección de este capítulo se detalla qué es un algoritmo genético y se plantean ejemplos de situaciones en las que es útil esta metaheurística.

A continuación se plantea que es una ecuación diferencial y se muestra un ejemplo de esta.

\section{Ecuaciones diferenciales}

Una ecuación diferencial se define como una ecuación que contiene las derivadas de una o más variables dependientes, con respecto a una o más variables independientes \cite{gaucel2014learning}. Una ecuación diferencial ordinaria (EDO) es una que contiene derivadas en función de una sola variable (por ejemplo, el tiempo). La forma general de una ecuación diferencial ordinaria es:

$$y'(t)=f(t, y(t)) \qquad y(t_0) = y_0$$

donde $y(t)$ es una función y $y_0$ es una condición inicial.

La solución de una ecuación diferencial es una función que al ser sustituida en la ecuación diferencial hace que se satisfaga dicha ecuación. Si además la ecuación diferencial es ordinaria, continua en un intervalo cerrado y se tienen condiciones iniciales, entonces la solución de dicha ecuación diferencial existe y es única. \cite{coddington1955theory}

Un ejemplo de ecuación diferencial ordinaria es:

$$y' = \frac{x^2}{y^3}$$

en donde la solución sería:

$$y = \sqrt[4]{\frac{4x}{3} + 4c}$$


\section{Ecuaciones diferenciales lineales con respecto a los parámetros}

Una ecuación diferencial es lineal con respecto a los parámetro si es de la forma

$$\frac{dX_i}{dt} = \sum_{i=1}^{n} a_i * f_i(t, y(t))$$

donde los $a_i$ son parámetros y todas las funciones $f_i(t,y)$ son funciones que dependen de la variable $t$, de la variable $y$, pero no dependen de ningún parámetro $a_i$.

Esta definición se puede extender a sistemas de ecuaciones diferenciales si todas las ecuaciones cumplen esta propiedad. Que el sistema sea lineal con repecto a los paráemtros permite modelar múltiples sistemas dinámicos poblaciones como el sistema de lotka volterra:

$$X' = \alpha * X - \beta * X * Y$$
$$Y' = \delta * X * Y - \gamma * Y$$

Para encontrar estos sistemas se utilizan diversas técnicas ya que muchas veces solo se poseen muestras de algún fenómeno físico en concreto y no se conoce las ecuaciones que lo describen, una de estas técnicas es la regresión.

\section{Regresión}

La regresión es un conjunto de procesos estadísticos para estimar las relaciones entre una o más variables dependientes y una o más variables independientes \cite{johnson2015applied}. Se explica la variable dependiente mientras que la independiente es la que se utiliza para explicar la variación de la variable dependiente. Se le llama regresión simple si solo se tienen dos variables, una dependiente y una independiente, en caso de que se posean más variables independiente se le llama regresión múltiple \cite{mann2007introductory}.

El análisis de regresión se puede utilizar para la predicción y el pronóstico de datos y en algunas situaciones, se puede utilizar el análisis de regresión para inferir relaciones causales entre las variables independientes y dependientes \cite{mann2007introductory}.

La primera forma de regresión fue el método de mínimos cuadrados, que fue publicado por Legendre en 1805, y por Gauss en 1809. Legendre y Gauss aplicaron el método al problema de determinar, a partir de observaciones astronómicas, las órbitas de los cuerpos alrededor del Sol, en su mayoría cometas, pero también más tarde los planetas menores recién descubiertos.

\section{Ajuste mínimo cuadrático de datos}

El método de mínimos cuadrados es un tipo de regresión que se utiliza para aproximar la solución de modelos en los que se conoce la función pero no sus parámetros. También se puede ver como un algoritmo para aproximar la solución de sistemas sobredeterminados, estos sistemas son conjuntos de ecuaciones en los que hay más ecuaciones que incógnitas.

Este método funciona minimizando la suma de los cuadrados de la diferencia entre un valor observado y el valor ajustado proporcionado por la función. Se puede expresar como resolver el problema de optimización de encontrar los valores de $\beta$ que minimizan $S$ dado el modelo $f$ y los puntos $(xi, yi)$ donde:

$$S = \sum_{i=1}^{n}(y_i - f(x_i, \beta))^2$$

Teniendo estos parámetros, se puede estimar la variable dependiente cuando las variables independientes toman un conjunto dado de valores. Este método se utiliza cuando la función es conocida, pero hay ocasiones en la práctica en las que esto no ocurre, para encontrar la función se puede utilizar un método llamado regresión simbólica.

\section{Regresión simbólica}

La regresión simbólica se utiliza para encontrar dentro de un espacio de funciones el modelo que mejor se ajuste a un conjunto de datos planteados. En este método, ningún modelo en particular se utiliza como punto de partida para la búsqueda del modelo que se desea encontrar. En su lugar se generan expresiones aleatorias que se forman combinando operaciones matemáticas, funciones analíticas, constantes y variables.

La introducción de la regresión simbólica generalmente se atribuye a John R. Koza \cite{zelinka2005analytic}. Koza mostró que la regresión simbólica puede usarse para descubrir modelos mediante la codificacion de expresiones matemáticas como árboles computacionales. En tales árboles, los nodos internos representan funciones ($+$, $-$, $*$, etc) que se extraen de un conjunto predeterminado de posibilidades, y los nodos hojas representan variables o constantes ($x_1$, $x_2$, $\dots$, $-1$, $\pi$, etc). Los parámetros en estos modelos usualmente se calculaban en el propio algoritmo o cada cierto tiempo se resolvía un problema de optimización pero esto es costoso.

Al no requerir una especificación a priori de un modelo, la regresión simbólica no se ve afectada por el desconocimiento de la estructura del modelo. Este método intenta descubrir las relaciones presentes en el conjunto de datos. Para lograr este fin, se prueban múltiples modelos posibles evaluando su calidad con respecto a alguna métrica de interés, en lugar de imponer una estructura de modelo que se considere matemáticamente manejable desde una perspectiva humana.

Para evaluar que tan cercano está el modelo obtenido con respecto al modelo original se define una función de ajuste. Esta hace que los resultados obtenidos a lo largo de la regresión simbólica sean cada vez mejores ya que tiene en cuenta no solo las métricas de error (valores que definen cuan cerca están los resultados obtenidos a los resultados deseados), sino cualquier métrica que desee definir el usuario con el objetivo de obtener un resultado con características específicas, por ejemplo modelos más pequeños o con menor cantidad de parámetros. Esto facilita el análisis posterior de los resultados al permitir asociar en el modelo obtenido algunos parámetros a significados de la vida real, por ejemplo la cantidad de individuos que mueren en cada instante de tiempo en el sistema de lotka volterra.

La regresión simbólica tiene la desventaja de además de ser un problema NP-difícil \cite{virgolin2022symbolic}, tener un espacio de búsqueda mucho más grande que otros tipos de problemas de ajustes de datos. Por ejemplo, tanto en la regresión lineal como no lineal, el espacio de búsqueda es $R^m$ y en la regresión simbólica se pueden explorar todas las funciones que van de $R^m$ a $R^n$.

Sin embargo, esta característica de poseer un espacio de búsqueda tan grande también tiene ventajas ya que el resultado pueden ser múltiples modelos y su correspondientes conjuntos de parámetros. Examinar esta colección de modelos resultantes permite al usuario identificar una solución que se ajuste mejor a alguna características en particular. Por ejemplo que el modelo posea ecuaciones con poca cantidad de parámetros o que la diferencia entre los datos evaluados en el modelo y los datos originales sea menor que un error específico.


\section{Regresión simbólica para EDOs}

La regresión simbólica ha sido utilizada de diversas maneras para encontrar sistemas de ecuaciones diferenciales, por ejemplo en el año 2014, un grupo de investigadores utilizaron esta técnica para encontrar sistemas dinámicos, generando para cada ecuación del sistema un grupo de ecuaciones. Luego probaban distintas combinaciones de las ecuaciones de estos subconjuntos hasta encontrar una que satisfaciera las condiciones de su investigación \cite{gaucel2014learning}. En el año 2008 se utilizó la regresión simbólica junto con el algoritmo de mínimos cuadrados para encontrar el sistema de ecuaciones diferenciales lineales en los parametros que mejor ajustase un conjunto de datos \cite{iba2008inference}

ver donde pongo esto:

Para funciones matemáticas, se utilizan diversos métodos en la regresión simbólica, uno de ellos es la recombinación de ecuaciones usando algoritmos evolutivos y uno de estos puede ser un algoritmo genético.

\section{Algoritmos genéticos}

Un algoritmo genético es una metaheurística inspirada en el proceso natural de selección \cite{mitchell1998introduction}. Son utilizados fundamentalmente para generar soluciones de alta calidad en problemas de optimización y búsqueda. Es un método para pasar de una población de "cromosomas" (por ejemplo, cadenas de unos y ceros, o "bits") a una nueva población mediante el uso de una especie de "selección natural" junto con los operadores inspirados en la genética de cruce, mutación y selección. Cada cromosoma consta de "genes" (por ejemplo, bits).

Los algoritmos genéticos son cómodos para resolver problemas de optimizacióon de la forma $min f(x)$, donde $x$ pertenece a un conjunto $C$ dado. Se le llama solución a cualquier $x$ de $C$. En dependencia de la estructura de $C$, las soluciones pueden tener distintas formas, por ejemplo vectores de números reales como en los problemas de optimización tradicionales o puedes ser árboles como en el caso de la regresión simbólica.

La evolución generalmente comienza a partir de una población de individuos generados aleatoriamente y es un proceso iterativo, se le llama generación a la población en cada iteración. En cada generación se evalúa la aptitud, o lo que quiere decir, el valor de la función objetivo en el problema de optimización que se está resolviendo de cada individuo de la población.

Los individuos más aptos se seleccionan de manera aleatoria de la población actual y las propiedades de estos se modifican utilizando las operaciones de mutación y cruzamiento para formar una nueva población. Esta nueva población toma el lugar de la población origen formando así una nueva generación de soluciones candidatas que se utiliza luego en la siguiente iteración del algoritmo. Comúnmente, el algoritmo termina cuando se ha producido un número máximo de generaciones o se ha alcanzado un nivel de aptitud satisfactorio para la población, también se puede detener el algoritmo en otras situaciones, por ejemplo que se haya recorrido todo el espacio de búsqueda, pero esto es poco usual debido al tamaño tan grande que suele tener este espacio.

El tamaño de la población depende de la naturaleza del problema, por ejemplo si intentamos minimizar el valor de una función convexa bastará con una población con una pequeña cantidad de individuos. Normalmente las poblaciones contiene varios cientos o miles de posibles soluciones ya el espacio de búsqueda suele ser grande. Como se menciona anteriormente, la población inicial suele generarse aleatoriamente, lo que permite explorar toda la gama de posibles soluciones en el espacio de búsqueda. Ocasionalmente, las soluciones pueden iniciarse en áreas donde es probable que se encuentren soluciones óptimas, por ejemplo si se desea encontrar el mínimo de una función, se pueden generar soluciones iniciales en donde la pendiente de la función evaluada en estas soluciones sea $0$ ya que esto es una condición necesaria para ser mínimo.

Durante cada generación, se selecciona una parte de la población para generar nuevos individuos. Las soluciones se seleccionan a través de un proceso basado en la aptitud, donde las soluciones más adecuadas medidas por una función de aptitud, suelen tener más probabilidades de ser seleccionadas, a este proceso se le llama selección. Algunos métodos de selección califican la aptitud de cada solución y seleccionan preferentemente las mejores soluciones asignando una mayor probabilidad de ser escogidas a estas, otros métodos califican solo una muestra aleatoria de la población, ya que el primer proceso puede llevar mucho tiempo.

Para generar una población de soluciones de una generación a otra se parte de los individuos seleccionados, a través de una combinación de operadores genéticos: mutación y cruzamiento. La mutación realiza cambios aleatorios en algún sitio del individuo seleccionado, por ejemplo si el individuo es la cadena 00000100, este puede ser mutado en su segunda posición para obtener 01000100. El cruzamiento intercambia subpartes aleatorias de dos individuos, obteniendo dos nuevos cromosomas. Por ejemplo, las cadenas 10000100 y 11111111 puedes ser cruzadas a partir de su tercera posición en cada una para producir 10011111 y 10011111. Resaltar que existen operaciones de cruzamiento en la que solo se obtiene un nuevo individuo como resultado de la operación.

Estas operaciones de cruzamiento, mutación y selección finalmente dan como resultado la población de soluciones de la próxima generación que es diferente de la generación inicial. Generalmente, la aptitud promedio habrá aumentado con este procedimiento para la población, ya que solo los mejores organismos de la primera generación junto con una pequeña proporción de soluciones menos aptas son seleccionados para reproducción. Estas soluciones menos aptas aseguran la diversidad genética dentro del acervo de características de los padres y, por lo tanto, aseguran la diversidad de propiedades de la siguiente generación de cromosomas.

La opinión sobre la importancia del cruzamiento frente a la mutación está dividida. Existen referencias en \cite{fogel2006evolutionary} que respaldan la importancia de la búsqueda basada en mutaciones.

Con el fin de recorrer de maneras distintas el espacio de búsqueda, vale la pena ajustar parámetros como la probabilidad de mutación, la probabilidad de cruzamiento y el tamaño de la población para encontrar configuraciones adecuadas para la clase de problema en la que se trabaja, por ejemplo una tasa de mutación muy pequeña puede conducir a la deriva genética, que es que desaparecen por completo algunos genes y se fijan los más frecuentes en las siguientes generaciones, resultando en una disminución en la diversidad genética de la población. Una tasa de cruzamiento demasiado alta puede conducir a una convergencia prematura del algoritmo genético. Un tamaño de población proporcional al espacio de búsqueda asegura suficiente diversidad genética para el problema que se desea solucionar, pero puede conducir a que la ejecución del algoritmo tome más tiempo y realice más cómpuntos.

Este proceso de creación de nuevas generaciones se repite hasta que se alcanza una condición de parada. Las condiciones de parada comunes son:

\begin{itemize}
    \item Se encuentra una solución que satisface criterios definidos por el usuario, pueden ser una cantidad de ajuste mínimo, o haber alcanzado un modelo más corto.
    \item Se alcanza el número máximo fijado de generaciones.
    \item Se alcanza la cantidad de tiempo o cómputo máximo asignado
    \item La aptitud de la solución con la clasificación más alta está alcanzando o ha alcanzado un nivel tal que las iteraciones sucesivas ya no producen mejores resultados.
    \item Combinaciones de lo anterior.
\end{itemize}

En este capitulo se han definido conceptos fundamentales para la completa comprensión de la propuesta de solución que utiliza regresión simbólica mediante un algoritmo genético para la obtención de un sistema de ecuaciones lineales con respecto a los parámetros. Para usar un algoritmo genético es necesario entonces definir varios elementos:

\begin{itemize}
    \item Cuáles son las posibles soluciones
    \item Cómo aplicar un operador de cruzamiento
    \item Cómo aplicar un operador de mutación
    \item Cómo determinar cuán buena es una solución
    \item Cómo determinar qué soluciones pasan a las próximas generaciones
\end{itemize}

Estos se defininen en el próximo capítulo.
